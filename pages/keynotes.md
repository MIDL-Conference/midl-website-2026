---
title: "Keynotes"
page_class: "keynotes"
---

{% from "_macros.html" import video %}

# Keynote speakers
<p><a id="keynoteX"></a></p>

## Ipek Oguz, Ph.D.![Portrait of Ipek Oguz](/images/IpekOguz.png){: width="180" }
### Associate Professor, Department of Computer Science, Department of Electrical and Computer Engineering, Vanderbilt University, USA.

<!-- ### McGill & CIFAR AI Chair ‚Äì Mila

<!-- üè† [Homepage](https://www.cim.mcgill.ca/~arbel/) -->
üéì [Google Scholar](https://scholar.google.com/citations?user=oHJIjVwAAAAJ&hl=zh-CN)
  
<!-- 
#### **The Promise of Causal Deep Learning for Personalized Medicine based on Medical Images: Towards Safe and Trustworthy Clinical Deployment**


<!-- **Abstract:** In current clinical practice, medical decisions are guided by broad demographic features and standardized clinical markers, which may not fully capture the nuances of the individual patients.  Personalized medicine, informed by medical images, has the potential to transform disease management by tailoring treatment decisions to the unique needs of individual patients, holding enormous potential to improve healthcare and drug development. Yet these models currently remain underexplored, and open challenges presented by real clinical contexts hinder their safe clinical deployment.  In this talk, I describe causal inference models for personalized medicine based on high dimensional medical images (MRI) acquired from patients with neurological disease, such as multiple sclerosis (MS), given their long-term, complex, heterogeneous evolutions and no cure. I will describe temporal causal models that permit learning the evolution of disease progression based from multimodal inputs.  Causal inference models then predict future individual factual and counterfactual progression trajectories on different treatments in latent space, as well as their associated individual treatment response trajectories. We then describe strategies to improve the safety and reliability of the models, such as building uncertainty-aware causal models for image-based personalized medicine. Extensive experiments large, multi-centre, randomized clinical trials for MS treatments illustrate the power of uncertainty-based causal inference frameworks to (a) accurately predict a patient‚Äôs future new lesional activity, continuous disability evolution, and treatment response to different drugs, and (b) discover subgroups of patients for which the models have high confidence in their response to treatments (even in clinical trials with no proven efficacy). -->


**Biography:**  Ipek Oguz is an Associate Professor in the Department of Computer Science at Vanderbilt University, with secondary appointments in Electrical and Computer Engineering and Biomedical Engineering. She received her Ph.D. in Computer Science at the University of North Carolina at Chapel Hill. Prior to joining Vanderbilt, she worked in the Penn Image Computing and Science Laboratory (PICSL) and Center for Biomedical Image Computing and Analytics (CBICA) at the University of Pennsylvania as well as in the Iowa Institute for Biomedical Imaging (IIBI) at the University of Iowa. Her research is in the field of medical image computing and specifically in the development of novel methodology for quantitative medical image analysis, with applications to ophthalmic imaging, obstetric imaging, endoscopic imaging and neuroimaging. Her technical interests include image segmentation, image synthesis and deep learning. She has co-authored more than 200 peer-reviewed journal and conference publications. She was a founding member of the Women in MICCAI Committee, and she is an Associate Editor for Medical Image Analysis and IEEE Transactions on Medical Imaging, and an Executive Editor for the Machine Learning for Biomedical Imaging journal. She served as program chair for MIDL 2023, and as general chair for IPMI 2025.

<!--{{ video("https://video.midl.io/2022/keynote1.mp4") }}-->
***
<p><a id="keynoteX"></a></p>

## 	Dean Ho, Ph.D.![Portrait of Dean Ho](/images/deanho.jpg){: width="180" }
### Provost‚Äôs Chair Professor, Department of Biomedical Engineering, National University of Singapore, Singapore.


<!-- 
<!-- üè† [Homepage](https://www.professoren.tum.de/rueckert-daniel) -->
üéì [Google Scholar](https://scholar.google.com/citations?user=cBWUh88AAAAJ&hl=en)

<!-- #### **AI and the Future of Radiology** -->


<!-- **Abstract:**  Artificial Intelligence (AI) is changing many fields across science and our society. This talk will discuss how AI is changing medicine and healthcare, particularly in radiology. I will focus on how AI can support the acquisition of medical images and image analysis and interpretation. This can enable the early detection of diseases and support the improved personalised diagnosis. I will show several examples of this in the talk, including cardiovascular MR imaging. Furthermore, we will discuss how AI solutions can be privacy-preserving while also providing trustworthy and explainable solutions for clinicians. -->


**Biography:**  Professor Dean Ho is currently Provost‚Äôs Chair Professor, Director of The Institute for Digital Medicine (WisDM) at the Yong Loo Lin School of Medicine; Director of The N.1 Institute for Health (N.1), and Head of the Department of Biomedical Engineering at the National University of Singapore (NUS).

Prof. Ho and team launched a first-in-kind trial - with Prof. Ho as the test subject - to optimise his performance and biomarkers with digital technologies. This study has been featured on television and digital media programming, and major global meetings. Prof. Ho and team also manage a portfolio of over 10 prospective, interventional human oncology clinical trials with life-saving outcomes. A serial entrepreneur, he has advised health/human performance teams, nutrition and wearable firms, and venture funds on digital medicine deployment.

Prof. Ho is an elected Fellow of the US National Academy of Inventors (NAI), American Association for the Advancement of Science (AAAS), the American Institute for Medical and Biological Engineering (AIMBE), and the Royal Society of Chemistry. Prof. Ho is Co-Chair of the World Health Organization (WHO) Working Group for the regulation of AI for Health.


<!--{{ video("https://video.midl.io/2022/keynote1.mp4") }}-->

***
<p><a id="keynoteX"></a></p>

## 	Junzhou Huang, Ph.D.![Portrait of Junzhou Huang](/images/JunzhouHuang.jpg){: width="180" }
###  Jenkins Garrett Professor, Department of Computer Science and Engineering, University of Texas at Arlington, USA.

<!-- <!-- üè† [Homepage](https://profiles.stanford.edu/mirabela-rusu) -->
üéì [Google Scholar](https://scholar.google.com/citations?user=X7KrguAAAAAJ&hl=en&oi=ao)

<!-- #### **Multimodal Learning for Early Cancer Detection in Low Resource Settings** -->
<!-- #### **Bridging the Radiology-Pathology Gap for Prostate Cancer Characterization**  -->


<!-- **Abstract:**  Clinical care is inherently multimodal, with medical image data collected throughout the patient‚Äôs journey.  For example, a patient at risk of cancer will undergo an ultrasound-guided biopsy, and when available with MRI revealing regions to be targeted due to higher risk to harbor aggressive disease. This biopsy procedure seeks to collect tissue samples for pathology and will inform treatment strategies for best outcomes. This common scenario provides unique opportunities for Artificial Intelligence (AI) methods to effectively integrate multimodal data, and learn imaging signatures in patients with known outcomes, to enable early cancer detection for patients at risk. My research focuses on developing AI methods that bridge the gap between highly informative modalities, e.g., pathology or MRI, and lower resolution modalities, e.g., ultrasound. These methods rely on multimodal image registration, image feature fusion, or integration of patient-specific data and population-specific information and rely on AI approaches for effective integration. While the learning is done with multiple imaging modalities, the inference requires only the low-resolution modality, e.g., ubiquitous conventional ultrasound, with applications in low-resource settings. These methods are applied to detect cancer and its aggressive extent in various cancers, e.g. prostate, kidney, or breast.   -->


**Biography:** Dr. Junzhou Huang is the Jenkins Garrett Professor in the Department of Computer Science and Engineering at the University of Texas at Arlington. He has served as a Director of the Machine Learning & Healthcare Center at Tencent AI Lab. He is an Amazon Scholar. His research interests include machine learning, medical image analysis, and bioinformatics, with a particular emphasis on developing novel machine learning methods for graph-structured data and their applications in biomedicine. His research focuses on (1) the development of scalable and interpretable machine learning algorithms for complex graph data; and (2) AI methods for extracting biologically and clinically meaningful information from multimodal pathology and pharmacology data, with applications in computational pathology, computational immunology, and computational drug discovery. His research has been supported by federal and state agencies (NSF, NIH, CPRIT) as well as industry partners (Google, Amazon, Microsoft, IBM, Samsung, XtalPi, Nokia, and Johnson & Johnson). His work has been widely published in top-tier AI, machine learning, and medical image analysis venues, and he has served in editorial and program committee roles for leading conferences and journals in the field.

<!--{{ video("https://video.midl.io/2022/keynote1.mp4") }}-->

<!-- ***
<p><a id="keynoteX"></a></p>

## Dr. Ismail Baris Turkbey, M.D.![Portrait of Ismail Baris Turkey](/images/keynotes/baris_turkbey.jpg){: width="180" }
### Director of the Artificial Intelligence Resource (AIR), Senior Clinician
### Center for Cancer Research, National Cancer Institute (NCI), National Institutes of Health (NIH)

üè† [Homepage](https://ccr.cancer.gov/staff-directory/ismail-baris-turkbey#qt-staff_profile_tabs-ui-tabs6)
üéì [Google Scholar](https://scholar.google.com/citations?user=XiMbUboAAAAJ&hl=en)

#### **Guiding Clinical Decisions in Localized Prostate Cancer with AI** 


**Abstract:**  Artificial Intelligence (AI) has become a prominent area of research in oncologic imaging, including prostate cancer. Despite numerous academic studies, the clinical translation of AI for guiding decision-making in localized prostate cancer care remains underexplored. This presentation will outline the critical steps for successfully integrating AI into clinical workflows. Topics include the development and validation of AI models using diverse datasets, strategies for deployment, and the prospective use of imaging-based AI in clinical decision-making. Insights from clinical trials on AI implementation will be shared, along with preliminary findings on the prognostic capabilities of AI models in predicting treatment outcomes and long-term prognosis.


**Biography:** Dr. Turkbey‚Äôs main research interests focus on prostate cancer imaging (multiparametric MRI, PET CT), prostate biopsy techniques, focal therapy for prostate cancer and artificial intelligence (segmentation, decision support systems). Dr. Turkbey is the Head of the Artificial Intelligence Resource (AIR), which makes AI tools available to CCR investigators with the goal of developing better screening and detection methods or predictive markers for patients.

<!--{{ video("https://video.midl.io/2022/keynote1.mp4") }}-->

***
<p><a id="keynoteX"></a></p>

## Mert Sabuncu, Ph.D.![Portrait of Mert Sabuncu](/images/MertSabuncu.JPG){: width="180" }
### Professor, School of Electrical and Computer Engineering, Cornell University and Cornell Tech, USA.

<!-- 
<!-- üè† [Homepage](https://www.aylward.org) -->
üéì [Google Scholar](https://scholar.google.com/citations?user=Pig-I4QAAAAJ&hl=zh-CN)


<!-- #### **MONAI For The Next Generation of Medical Technologies** -->

<!-- **Abstract:** MONAI is an open-source platform for medical AI that has been downloaded over 3.5M times, featured in hundreds of publications, used to win numerous medical image analysis challenges, and integrated into every major cloud-base healthcare platform as well as multiple regulatory-approved clinical products.   This presentation will explore the use of MONAI in the discovery and development of future medical products.  That future involves the intertwining of training, simulation, and execution to train and control robots, optimize equipment ergonomics, and inspire new forms of monitoring and intervention.  That future will be built on open source: MONAI, Omniverse, and the Holoscan SDK. -->

**Biography:**  Mert R. Sabuncu is a Professor of Electrical and Computer Engineering at Cornell University and Cornell Tech, with a dual appointment in Radiology at Weill Cornell Medicine, where he serves as Vice Chair of AI and Engineering Research. His research focuses on the development of machine-learning‚Äìbased computational methods for biomedical imaging, spanning image acquisition, segmentation, multimodal data integration, and clinical translation.

Dr. Sabuncu received his Ph.D. in Electrical Engineering from Princeton University, where his dissertation introduced entropy-based approaches to image registration. He subsequently completed postdoctoral training at Massachusetts Institute of Technology, working with Polina Golland at the Computer Science and Artificial Intelligence Laboratory on biomedical image analysis, including brain MRI segmentation and population modeling.

He later joined the A.A. Martinos Center for Biomedical Imaging at Massachusetts General Hospital and Harvard Medical School as junior faculty, where he established an independent research program at the intersection of medical imaging, machine learning, and genetics.

Dr. Sabuncu is a recipient of the NIH Early Career Development (K) Award and the NSF CAREER Award, and he serves as Editor-in-Chief of Machine Learning for Biomedical Image Analysis (MELBA).

<!--{{ video("https://video.midl.io/2022/keynote1.mp4") }}-->
